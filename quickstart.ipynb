{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/transformers/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# # OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50257])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Manhattan bridge is a major artery for the city's subway system, and the bridge is one of the busiest in the country.\n",
      "\n",
      "The bridge is one of the busiest in the country.\n",
      "\n",
      "The bridge is one of the busiest in the country.\n",
      "\n",
      "The bridge is one of the busiest in the country.\n",
      "\n",
      "The bridge is one of the busiest in the country.\n",
      "\n",
      "The bridge is one of the busiest in the country.\n",
      "\n",
      "The bridge is one of the busiest in the country\n"
     ]
    }
   ],
   "source": [
    "generated = tokenizer.encode(\"The Manhattan bridge\")\n",
    "context = torch.tensor([generated])\n",
    "past = None\n",
    "\n",
    "for i in range(100):\n",
    "    #print(i)\n",
    "    output, past = model(context, past=past)\n",
    "    token = torch.argmax(output[..., -1, :])\n",
    "\n",
    "    generated += [token.tolist()]\n",
    "    context = token.unsqueeze(0)\n",
    "\n",
    "sequence = tokenizer.decode(generated)\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/huggingface/transformers/tree/master/examples/language-modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
