{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "eos = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath = 'data/user/suncoasthost/*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(inputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_prop = .1\n",
    "shuffled_indices = list(np.random.choice(range(len(fnames)), len(fnames), replace=False))\n",
    "valid_size = max(1, int(valid_prop*len(fnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_shuffled = [fnames[i] for i in shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_test = fnames_shuffled[:valid_size]\n",
    "fnames_valid = fnames_shuffled[valid_size:2*valid_size]\n",
    "fnames_train = fnames_shuffled[2*valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qa_string(comment):\n",
    "    context = 'In subreddit: {subname}\\nTitle: {title}\\n{body}'.format(\n",
    "        subname = comment['submission']['subreddit'],\n",
    "        title = comment['submission']['title'],\n",
    "        body = comment['submission']['selftext'],\n",
    "    )\n",
    "    return '{context}\\n\\nQ: {q}\\nA: {a}'.format(\n",
    "        context = context,\n",
    "        q = 'What do you think?' if comment['parent_comment'] is None else comment['parent_comment']['body'],\n",
    "        a = comment['comment']['body'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath = 'data/finetune/suncoasthost'\n",
    "os.makedirs(outputpath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_text(fnames, outputfname):\n",
    "    # clear destination\n",
    "    with open(outputfname, 'w+') as f:\n",
    "        f.write('')\n",
    "    \n",
    "    total = len(fnames)\n",
    "    i = 0\n",
    "    for fname in fnames:\n",
    "        print ('[{}/{}]'.format(i, total))\n",
    "        i += 1\n",
    "        with open(fname) as f:\n",
    "            comment = json.load(f)\n",
    "        with open(outputfname, 'a+') as f:\n",
    "            f.write('{body}\\n{eos}\\n'.format(\n",
    "                body=get_qa_string(comment),\n",
    "                eos=eos\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test.txt\n",
      "[0/15]\n",
      "[1/15]\n",
      "[2/15]\n",
      "[3/15]\n",
      "[4/15]\n",
      "[5/15]\n",
      "[6/15]\n",
      "[7/15]\n",
      "[8/15]\n",
      "[9/15]\n",
      "[10/15]\n",
      "[11/15]\n",
      "[12/15]\n",
      "[13/15]\n",
      "[14/15]\n",
      "\n",
      "valid.txt\n",
      "[0/15]\n",
      "[1/15]\n",
      "[2/15]\n",
      "[3/15]\n",
      "[4/15]\n",
      "[5/15]\n",
      "[6/15]\n",
      "[7/15]\n",
      "[8/15]\n",
      "[9/15]\n",
      "[10/15]\n",
      "[11/15]\n",
      "[12/15]\n",
      "[13/15]\n",
      "[14/15]\n",
      "\n",
      "train.txt\n",
      "[0/129]\n",
      "[1/129]\n",
      "[2/129]\n",
      "[3/129]\n",
      "[4/129]\n",
      "[5/129]\n",
      "[6/129]\n",
      "[7/129]\n",
      "[8/129]\n",
      "[9/129]\n",
      "[10/129]\n",
      "[11/129]\n",
      "[12/129]\n",
      "[13/129]\n",
      "[14/129]\n",
      "[15/129]\n",
      "[16/129]\n",
      "[17/129]\n",
      "[18/129]\n",
      "[19/129]\n",
      "[20/129]\n",
      "[21/129]\n",
      "[22/129]\n",
      "[23/129]\n",
      "[24/129]\n",
      "[25/129]\n",
      "[26/129]\n",
      "[27/129]\n",
      "[28/129]\n",
      "[29/129]\n",
      "[30/129]\n",
      "[31/129]\n",
      "[32/129]\n",
      "[33/129]\n",
      "[34/129]\n",
      "[35/129]\n",
      "[36/129]\n",
      "[37/129]\n",
      "[38/129]\n",
      "[39/129]\n",
      "[40/129]\n",
      "[41/129]\n",
      "[42/129]\n",
      "[43/129]\n",
      "[44/129]\n",
      "[45/129]\n",
      "[46/129]\n",
      "[47/129]\n",
      "[48/129]\n",
      "[49/129]\n",
      "[50/129]\n",
      "[51/129]\n",
      "[52/129]\n",
      "[53/129]\n",
      "[54/129]\n",
      "[55/129]\n",
      "[56/129]\n",
      "[57/129]\n",
      "[58/129]\n",
      "[59/129]\n",
      "[60/129]\n",
      "[61/129]\n",
      "[62/129]\n",
      "[63/129]\n",
      "[64/129]\n",
      "[65/129]\n",
      "[66/129]\n",
      "[67/129]\n",
      "[68/129]\n",
      "[69/129]\n",
      "[70/129]\n",
      "[71/129]\n",
      "[72/129]\n",
      "[73/129]\n",
      "[74/129]\n",
      "[75/129]\n",
      "[76/129]\n",
      "[77/129]\n",
      "[78/129]\n",
      "[79/129]\n",
      "[80/129]\n",
      "[81/129]\n",
      "[82/129]\n",
      "[83/129]\n",
      "[84/129]\n",
      "[85/129]\n",
      "[86/129]\n",
      "[87/129]\n",
      "[88/129]\n",
      "[89/129]\n",
      "[90/129]\n",
      "[91/129]\n",
      "[92/129]\n",
      "[93/129]\n",
      "[94/129]\n",
      "[95/129]\n",
      "[96/129]\n",
      "[97/129]\n",
      "[98/129]\n",
      "[99/129]\n",
      "[100/129]\n",
      "[101/129]\n",
      "[102/129]\n",
      "[103/129]\n",
      "[104/129]\n",
      "[105/129]\n",
      "[106/129]\n",
      "[107/129]\n",
      "[108/129]\n",
      "[109/129]\n",
      "[110/129]\n",
      "[111/129]\n",
      "[112/129]\n",
      "[113/129]\n",
      "[114/129]\n",
      "[115/129]\n",
      "[116/129]\n",
      "[117/129]\n",
      "[118/129]\n",
      "[119/129]\n",
      "[120/129]\n",
      "[121/129]\n",
      "[122/129]\n",
      "[123/129]\n",
      "[124/129]\n",
      "[125/129]\n",
      "[126/129]\n",
      "[127/129]\n",
      "[128/129]\n"
     ]
    }
   ],
   "source": [
    "print ('\\ntest.txt')\n",
    "write_to_text(fnames_test, os.path.join(outputpath, 'test.txt'))\n",
    "print ('\\nvalid.txt')\n",
    "write_to_text(fnames_valid, os.path.join(outputpath, 'valid.txt'))\n",
    "print ('\\ntrain.txt')\n",
    "write_to_text(fnames_train, os.path.join(outputpath, 'train.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
